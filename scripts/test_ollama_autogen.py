#!/usr/bin/env python3
"""–¢–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è Ollama –∏ AutoGen"""

import autogen
import os
import sys
from pathlib import Path

# –î–æ–±–∞–≤–∏—Ç—å –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –≤ –ø—É—Ç—å
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from dotenv import load_dotenv

load_dotenv()


def test_ollama_connection():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Ollama"""
    import requests

    base_url = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")
    model = os.getenv("OLLAMA_MODEL", "qwen2.5:7b")

    try:
        print(f"üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Ollama...")
        print(f"   URL: {base_url}")
        print(f"   –ú–æ–¥–µ–ª—å: {model}")

        response = requests.post(
            f"{base_url}/api/generate",
            json={
                "model": model,
                "prompt": "–ü—Ä–∏–≤–µ—Ç! –û—Ç–≤–µ—Ç—å –æ–¥–Ω–∏–º —Å–ª–æ–≤–æ–º: —Ä–∞–±–æ—Ç–∞–µ—Ç?",
                "stream": False
            },
            timeout=10
        )

        if response.status_code == 200:
            result = response.json()
            print(f"‚úÖ Ollama –ø–æ–¥–∫–ª—é—á–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
            print(f"üìù –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏: {result.get('response', 'N/A')[:100]}")
            return True
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {response.status_code}")
            print(f"   –û—Ç–≤–µ—Ç: {response.text[:200]}")
            return False
    except requests.exceptions.ConnectionError:
        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Ollama")
        print(f"   –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ Ollama –∑–∞–ø—É—â–µ–Ω: ollama serve")
        return False
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        return False


def test_autogen():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç—ã AutoGen"""
    try:
        print(f"\nüîç –ü—Ä–æ–≤–µ—Ä–∫–∞ AutoGen...")

        config_list = [
            {
                "model": os.getenv("OLLAMA_MODEL", "qwen2.5:7b"),
                "base_url": os.getenv("OLLAMA_BASE_URL", "http://localhost:11434"),
                "api_key": "ollama",
                "api_type": "open_ai",
            }
        ]

        assistant = autogen.AssistantAgent(
            name="test_assistant",
            llm_config={"config_list": config_list},
        )

        print("‚úÖ AutoGen –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —É—Å–ø–µ—à–Ω–æ!")
        return True
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ AutoGen: {e}")
        print(f"   –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ AutoGen —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: pip install pyautogen")
        return False


if __name__ == "__main__":
    print("="*60)
    print("üîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Ollama –∏ AutoGen")
    print("="*60)
    print()

    print("1. –ü—Ä–æ–≤–µ—Ä–∫–∞ Ollama...")
    ollama_ok = test_ollama_connection()

    print("\n2. –ü—Ä–æ–≤–µ—Ä–∫–∞ AutoGen...")
    autogen_ok = test_autogen()

    print("\n" + "="*60)
    if ollama_ok and autogen_ok:
        print("‚úÖ –í—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ–π–¥–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ!")
        print("üöÄ Ollama –∏ AutoGen –≥–æ—Ç–æ–≤—ã –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")
        sys.exit(0)
    else:
        print("‚ùå –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Ç–µ—Å—Ç—ã –Ω–µ –ø—Ä–æ—à–ª–∏. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏.")
        print("\nüìã –ß–µ–∫-–ª–∏—Å—Ç:")
        if not ollama_ok:
            print("   - [ ] Ollama —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: ollama --version")
            print("   - [ ] Ollama –∑–∞–ø—É—â–µ–Ω: ollama serve")
            print("   - [ ] –ú–æ–¥–µ–ª—å —Å–∫–∞—á–∞–Ω–∞: ollama pull qwen2.5:7b")
        if not autogen_ok:
            print("   - [ ] AutoGen —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: pip install pyautogen")
            print("   - [ ] –í–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–æ: source .venv/bin/activate")
        sys.exit(1)


